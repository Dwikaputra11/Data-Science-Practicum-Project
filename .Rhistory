<<<<<<< HEAD
library(syuzhet)
library(here)
library(readxl)
library(vroom)
library(tm)
data <- read_excel(path = here('data-raw/review_gwk.xlsx'))
install.packages(path)
data <- read_excel(path = here('data-raw/review_gwk.xlsx'))
knitr::opts_chunk$set(echo = TRUE)
library(syuzhet) #untuk membaca fungsi get_nrc
dataLabel<- read.csv("labeling.csv")
ui <- fluidPage(
titlePanel("Analisis sentimen GWK"),
mainPanel(
tabsetPanel(type = "tabs",
#NB
tabPanel("Term Document Matrix and Statistic", verbatimTextOutput("result")),
#scatterplot
tabPanel("Analisis Emosi", plotOutput("scatterplot")),
# Plot
tabPanel("Data", DT::dataTableOutput('tbl1')),
#frekuensi data
#tabPanel("Frequency Word ", plotOutput("frequencyword")width = 500),
# Output Data Dalam Tabel
tabPanel("Wordcloud", wordcloud2Output("Wordcloud"))
)
)
)
=======
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan
corpus.clean<-corpus%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c("can","with","was","its","you","but","get","am","is","are","not","the","that", "and", "from", "this", "us", "for", "which","too", "but","there","also","have","only", "were","has","than","very","they","still","will","when","to","your","dont","just","need"))%>%
tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:50,]
df.test<-data.frame[51:100,]
dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]
corpus.clean.train<-corpus.clean[1:50]
corpus.clean.test<-corpus.clean[51:100]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
#dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
kalimat2<-read.csv("Review_GWK_Clean.csv",header=T)
#skoring
kata.positif <- scan("positive-words.txt",what="character",comment.char=";")
kata.negatif <- scan("negative-words.txt",what="character",comment.char=";")
score.sentiment = function(kalimat2, positif, negatif,
.progress='none')
{
require(plyr)
require(stringr)
scores = laply(kalimat2, function(kalimat, positif,
negatif) {
kalimat = gsub('[[:punct:]]', '', kalimat)
kalimat = gsub('[[:cntrl:]]', '', kalimat)
kalimat = gsub('\\d+', '', kalimat)
kalimat = tolower(kalimat)
list.kata = str_split(kalimat, '\\s+')
kata2 = unlist(list.kata)
positif.matches = match(kata2, kata.positif)
negatif.matches = match(kata2, kata.negatif)
positif.matches = !is.na(positif.matches)
negatif.matches = !is.na(negatif.matches)
score = sum(positif.matches) - (sum(negatif.matches))
return(score)
}, kata.positif, kata.negatif, .progress=.progress )
scores.df = data.frame(score=scores, text=kalimat2)
return(scores.df)}
hasil = score.sentiment(kalimat2$text, kata.positif, kata.negatif)
#mengubah nilai score menjadi sentimen
hasil$klasifikasi<- ifelse(hasil$score<0, "Negatif",ifelse(hasil$score==0,"Netral","Positif"))
hasil$klasifikasi
#menukar urutan baris
data <- hasil[c(3,1,2)]
#View(data)
write.csv(data, file = "viewdata.csv")
knitr::opts_chunk$set(echo = TRUE)
require(corpus)
data.frame<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = F)
glimpse(data.frame)
>>>>>>> a9a116762fe2276d1bf12bf46bae84217cdba960
library(tm)
library(wordcloud2)
library(vroom)
library(here)
library(RTextTools)
library(dplyr)
library(wordcloud)
library(shiny)
library(ggplot2)
library(plotly)
library(e1071)
library(caret)
library(syuzhet)
library(here)
library(readxl)
library(vroom)
library(tm)
<<<<<<< HEAD
data <- read_excel(path = here('data-raw/review_gwk.xlsx'))
review <- data$review
review.vector <- Corpus(VectorSource(review))
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
reviewclean <- tm_map(review.vector, removeURL)
removeNL <- function(y) gsub("\n", " ", y)
reviewclean <- tm_map(review.vector, removeNL)
replacecomma <- function(y) gsub(",", "", y)
reviewclean <- tm_map(reviewclean, replacecomma)
removetitik2 <- function(y) gsub(":", "", y)
reviewclean <- tm_map(reviewclean, removetitik2)
removetitikkoma <- function(y) gsub(";", " ", y)
reviewclean <- tm_map(reviewclean, removetitikkoma)
removeamp <- function(y) gsub("&amp", "", y)
reviewclean <- tm_map(reviewclean, removeamp)
removeUN <- function(z) gsub("@\\w+", "", z)
reviewclean <- tm_map(reviewclean, removeUN)
remove.all <- function(xy) gsub("[^[:alpha:][:space:]]*", "", xy)
reviewclean <- tm_map(reviewclean, remove.all)
remove.emoticon <- function(x) gsub("[^\x01-\x7F]", "", x)
reviewclean <- tm_map(reviewclean, remove.emoticon)
reviewclean <- tm_map(reviewclean, removePunctuation)
reviewclean <- tm_map(reviewclean, tolower)
frame.data <- data.frame(text=unlist(sapply(reviewclean,`[`)), stringsAsFactors = F)
View(frame.data)
write.csv(frame.data, file = 'Review_GWK_Clean.csv')
data.clean<-read.csv("Review_GWK_Clean.csv",header=T)
#skoring
kata.positif <- scan("positive-words.txt",what="character",comment.char=";")
kata.negatif <- scan("negative-words.txt",what="character",comment.char=";")
score.sentiment = function(sentence, positif, negatif,
.progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentence, function(kalimat, positif,
negatif) {
kalimat = gsub('[[:punct:]]', '', kalimat)
kalimat = gsub('[[:cntrl:]]', '', kalimat)
kalimat = gsub('\\d+', '', kalimat)
kalimat = tolower(kalimat)
list.kata = str_split(kalimat, '\\s+')
kata2 = unlist(list.kata)
positif.matches = match(kata2, kata.positif)
negatif.matches = match(kata2, kata.negatif)
positif.matches = !is.na(positif.matches)
negatif.matches = !is.na(negatif.matches)
score = sum(positif.matches) - (sum(negatif.matches))
return(score)
}, kata.positif, kata.negatif, .progress=.progress )
scores.df = data.frame(score=scores, text=sentence)
return(scores.df)}
hasil = score.sentiment(data.clean$text, kata.positif, kata.negatif)
#CONVERT SCORE TO SENTIMENT
hasil$klasifikasi<- ifelse(hasil$score<0, "Negatif",ifelse(hasil$score==0,"Netral","Positif"))
hasil$klasifikasi
View(hasil)
#EXCHANGE ROW SEQUENCE
data <- hasil[c(3,1,2)] #ubah urutan kolom
View(data)
write.csv(data, file = "labeling.csv")
review.data <- read.csv("Review_GWK_Clean.csv", stringsAsFactors = F)
review <- as.character(review.data$text)
s <- get_nrc_sentiment(review)
review.combine <- cbind(review.data$text, s)
par(mar=rep(3,4))
a <- barplot(colSums(s), col=rainbow(10),ylab='count',main='Analisis sentimen GWK')
brplt <- a
review.data <- read.csv("Review_GWK_Clean.csv", stringsAsFactors = F)
review <- as.character(review.data$text)
s <- get_nrc_sentiment(review)
review.combine <- cbind(review.data$text, s)
par(mar=rep(3,4))
a <- barplot(colSums(s), col=rainbow(10),ylab='count',main='Analisis sentimen GWK')
brplt <- a
=======
require(corpus)
data.frame<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = F)
glimpse(data.frame)
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
corpus<-Corpus(VectorSource(data.frame$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan
corpus.clean<-corpus%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c("can","with","was","its","you","but","get","am","is","are","not","the","that", "and", "from", "this", "us", "for", "which","too", "but","there","also","have","only", "were","has","than","very","they","still","will","when","to","your","dont","just","need"))%>%
tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:50,]
df.test<-data.frame[51:100,]
dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]
corpus.clean.train<-corpus.clean[1:50]
corpus.clean.test<-corpus.clean[51:100]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
#Boolan Naive Bayes
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
#Naive Bayes Model
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)
#Training
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 1)
require(corpus)
data.frame<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = F)
glimpse(data.frame)
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
corpus<-Corpus(VectorSource(data.frame$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan
corpus.clean<-corpus%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c("can","with","was","its","you","but","get","am","is","are","not","the","that", "and", "from", "this", "us", "for", "which","too", "but","there","also","have","only", "were","has","than","very","they","still","will","when","to","your","dont","just","need"))%>%
tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:50,]
df.test<-data.frame[51:100,]
dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]
corpus.clean.train<-corpus.clean[1:50]
corpus.clean.test<-corpus.clean[51:100]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
#Boolan Naive Bayes
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
#Naive Bayes Model
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,2,convert_count)
#Training
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 1)
require(corpus)
data.frame<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = F)
glimpse(data.frame)
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
corpus<-Corpus(VectorSource(data.frame$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan
corpus.clean<-corpus%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c("can","with","was","its","you","but","get","am","is","are","not","the","that", "and", "from", "this", "us", "for", "which","too", "but","there","also","have","only", "were","has","than","very","they","still","will","when","to","your","dont","just","need"))%>%
tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:340,]
df.test<-data.frame[341:680,]
dtm.train<-dtm[1:340,]
dtm.test<-dtm[341:680,]
corpus.clean.train<-corpus.clean[1:340]
corpus.clean.test<-corpus.clean[341:680]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
#Boolan Naive Bayes
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
#Naive Bayes Model
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,2,convert_count)
#Training
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 1)
View(trainNB)
require(corpus)
data.frame<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = F)
glimpse(data.frame)
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
corpus<-Corpus(VectorSource(data.frame$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan
corpus.clean<-corpus%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c("can","with","was","its","you","but","get","am","is","are","not","the","that", "and", "from", "this", "us", "for", "which","too", "but","there","also","have","only", "were","has","than","very","they","still","will","when","to","your","dont","just","need"))%>%
tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:340,]
df.test<-data.frame[341:680,]
dtm.train<-dtm[1:340,]
dtm.test<-dtm[341:680,]
corpus.clean.train<-corpus.clean[1:340]
corpus.clean.test<-corpus.clean[341:680]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
#Boolan Naive Bayes
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
#Naive Bayes Model
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,2,convert_count)
#Training
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 2)
require(corpus)
data.frame<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = F)
glimpse(data.frame)
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
corpus<-Corpus(VectorSource(data.frame$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan
corpus.clean<-corpus%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c("can","with","was","its","you","but","get","am","is","are","not","the","that", "and", "from", "this", "us", "for", "which","too", "but","there","also","have","only", "were","has","than","very","they","still","will","when","to","your","dont","just","need"))%>%
tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:340,]
df.test<-data.frame[341:680,]
dtm.train<-dtm[1:340,]
dtm.test<-dtm[341:680,]
corpus.clean.train<-corpus.clean[1:340]
corpus.clean.test<-corpus.clean[341:680]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
#Boolan Naive Bayes
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
#Naive Bayes Model
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,2,convert_count)
#Training
classifier <- naiveBayes(trainNB, df.train$text, laplace = 2)
#Use the NB classifier we built to make predictions on the test set
pred <- predict(classifier, testNB)
#Create a truth table by tabulating the predicted class labels with the actual predicted class labels with the actual class labels
NB_table=table("Prediction"= pred, "Actual" = df.test$klasifikasi)
#Create a truth table by tabulating the predicted class labels with the actual predicted class labels with the actual class labels
NB_table=table("Prediction"= pred, "Actual" = df.test$)
require(corpus)
data.frame<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = F)
glimpse(data.frame)
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
corpus<-Corpus(VectorSource(data.frame$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan
corpus.clean<-corpus%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c("can","with","was","its","you","but","get","am","is","are","not","the","that", "and", "from", "this", "us", "for", "which","too", "but","there","also","have","only", "were","has","than","very","they","still","will","when","to","your","dont","just","need"))%>%
tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:340,]
df.test<-data.frame[341:680,]
dtm.train<-dtm[1:340,]
dtm.test<-dtm[341:680,]
corpus.clean.train<-corpus.clean[1:340]
corpus.clean.test<-corpus.clean[341:680]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
#Boolan Naive Bayes
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
#Naive Bayes Model
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,2,convert_count)
#Training
classifier <- naiveBayes(trainNB, df.train$text, laplace = 2)
#Use the NB classifier we built to make predictions on the test set
pred <- predict(classifier, testNB)
#Create a truth table by tabulating the predicted class labels with the actual predicted class labels with the actual class labels
NB_table=table("Prediction"= pred, "Actual" = df.test$text)
NB_table
#confussion Matrix
conf.matNB <- confusionMatrix(pred, df.test$text)
View(classifier)
View(data.frame)
data.frame<-read.csv("labeling.csv",stringsAsFactors = F)
>>>>>>> a9a116762fe2276d1bf12bf46bae84217cdba960
require(corpus)
data.frame<-read.csv("labeling.csv",stringsAsFactors = F)
data.frame$klasifikasi <- factor(data.frame$klasifikasi)
glimpse(data.frame)
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
corpus<-Corpus(VectorSource(data.frame$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan
corpus.clean<-corpus%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c("can","with","was","its","you","but","get","am","is","are","not","the","that", "and", "from", "this", "us", "for", "which","too", "but","there","also","have","only", "were","has","than","very","they","still","will","when","to","your","dont","just","need"))%>%
tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:340,]
df.test<-data.frame[341:680,]
dtm.train<-dtm[1:340,]
dtm.test<-dtm[341:680,]
corpus.clean.train<-corpus.clean[1:340]
corpus.clean.test<-corpus.clean[341:680]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
#Boolan Naive Bayes
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
#Naive Bayes Model
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,2,convert_count)
#Training
<<<<<<< HEAD
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 1)
=======
classifier <- naiveBayes(trainNB, df.train$klasifiksi, laplace = 2)
require(corpus)
data.frame<-read.csv("labeling.csv",stringsAsFactors = F)
data.frame$klasifikasi <- factor(data.frame$klasifikasi)
glimpse(data.frame)
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
corpus<-Corpus(VectorSource(data.frame$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan
corpus.clean<-corpus%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c("can","with","was","its","you","but","get","am","is","are","not","the","that", "and", "from", "this", "us", "for", "which","too", "but","there","also","have","only", "were","has","than","very","they","still","will","when","to","your","dont","just","need"))%>%
tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:340,]
df.test<-data.frame[341:680,]
dtm.train<-dtm[1:340,]
dtm.test<-dtm[341:680,]
corpus.clean.train<-corpus.clean[1:340]
corpus.clean.test<-corpus.clean[341:680]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
#Boolan Naive Bayes
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
#Naive Bayes Model
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,2,convert_count)
#Training
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 2)
>>>>>>> a9a116762fe2276d1bf12bf46bae84217cdba960
#Use the NB classifier we built to make predictions on the test set
pred <- predict(classifier, testNB)
#Create a truth table by tabulating the predicted class labels with the actual predicted class labels with the actual class labels
NB_table=table("Prediction"= pred, "Actual" = df.test$klasifikasi)
NB_table
#confussion Matrix
conf.matNB <- confusionMatrix(pred, df.test$klasifikasi)
conf.matNB
library(syuzhet) #untuk membaca fungsi get_nrc
<<<<<<< HEAD
dataLabel<- read.csv("labeling.csv")
=======
dataLabel<- read.csv("viewdata.csv")
>>>>>>> a9a116762fe2276d1bf12bf46bae84217cdba960
ui <- fluidPage(
titlePanel("Analisis sentimen GWK"),
mainPanel(
tabsetPanel(type = "tabs",
<<<<<<< HEAD
#NB
tabPanel("Term Document Matrix and Statistic", verbatimTextOutput("result")),
#scatterplot
tabPanel("Analisis Emosi", plotOutput("scatterplot")),
# Plot
tabPanel("Data", DT::dataTableOutput('tbl1')),
#frekuensi data
#tabPanel("Frequency Word ", plotOutput("frequencyword")width = 500),
# Output Data Dalam Tabel
tabPanel("Wordcloud", wordcloud2Output("Wordcloud"))
=======
tabPanel("Bagan", plotOutput("scatterplot")),
# Plot
tabPanel("Data", DT::dataTableOutput('tbl1')),
# Output Data Dalam Tabel
tabPanel("Wordcloud", plotOutput("Wordcloud"))
>>>>>>> a9a116762fe2276d1bf12bf46bae84217cdba960
)
)
)
# SERVER
server <- function(input, output) {
# Output Data
output$tbl1 = DT::renderDataTable({
DT::datatable(dataLabel, options = list(lengthChange = FALSE))
})
<<<<<<< HEAD
output$result <-renderPrint({
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 1)
NB_table=table("Prediction"= pred, "Actual" = df.test$klasifikasi)
conf.matNB <- confusionMatrix(pred, df.test$klasifikasi)
conf.matNB
})
output$scatterplot <- renderPlot(
{
produk_dataset<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = FALSE)
=======
output$scatterplot <- renderPlot({produk_dataset<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = FALSE)
>>>>>>> a9a116762fe2276d1bf12bf46bae84217cdba960
review <-as.character(produk_dataset$text)
s<-get_nrc_sentiment(review)
review_combine<-cbind(produk_dataset$text,s)
par(mar=rep(3,4))
barplot(colSums(s),col= rainbow(10),ylab='count',main='Analisis sentimen GWK')
<<<<<<< HEAD
},
height=400)
output$Wordcloud <- wordcloud2Output({
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:50,]
df.test<-data.frame[51:100,]
dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
#dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
#output$frequencyword <-renderPlot({
#barplot(a[1:10,]$freq, las = 2, names.arg = a[1:10,]$word,
#col ="lightgreen", main ="Most frequent words",
#ylab = "Word frequencies")
})
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
})
library(syuzhet) #untuk membaca fungsi get_nrc
dataLabel<- read.csv("labeling.csv")
ui <- fluidPage(
titlePanel("Analisis sentimen GWK"),
mainPanel(
tabsetPanel(type = "tabs",
#NB
tabPanel("Term Document Matrix and Statistic", verbatimTextOutput("result")),
#scatterplot
tabPanel("Analisis Emosi", plotOutput("scatterplot")),
# Plot
tabPanel("Data", DT::dataTableOutput('tbl1')),
# Output Data Dalam Tabel
tabPanel("Wordcloud", wordcloud2Output("Wordcloud"))
)
)
)
# SERVER
server <- function(input, output) {
# Output Data
output$tbl1 = DT::renderDataTable({
DT::datatable(dataLabel, options = list(lengthChange = FALSE))
})
output$result <-renderPrint({
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 1)
NB_table=table("Prediction"= pred, "Actual" = df.test$klasifikasi)
conf.matNB <- confusionMatrix(pred, df.test$klasifikasi)
conf.matNB
})
output$scatterplot <- renderPlot(
{
produk_dataset<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = FALSE)
review <-as.character(produk_dataset$text)
s<-get_nrc_sentiment(review)
review_combine<-cbind(produk_dataset$text,s)
par(mar=rep(3,4))
barplot(colSums(s),col= rainbow(10),ylab='count',main='Analisis sentimen GWK')
},
height=400)
output$Wordcloud <- wordcloud2Output({
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:50,]
df.test<-data.frame[51:100,]
dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
#dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
})
}
shinyApp(ui = ui, server = server)
library(syuzhet) #untuk membaca fungsi get_nrc
dataLabel<- read.csv("labeling.csv")
ui <- fluidPage(
titlePanel("Analisis sentimen GWK"),
mainPanel(
tabsetPanel(type = "tabs",
#NB
tabPanel("Term Document Matrix and Statistic", verbatimTextOutput("result")),
#scatterplot
tabPanel("Analisis Emosi", plotOutput("scatterplot")),
# Plot
tabPanel("Data", DT::dataTableOutput('tbl1')),
# Output Data Dalam Tabel
tabPanel("Wordcloud", wordcloud2Output("Wordcloud"))
)
)
)
# SERVER
server <- function(input, output) {
# Output Data
output$tbl1 = DT::renderDataTable({
DT::datatable(dataLabel, options = list(lengthChange = FALSE))
})
output$result <-renderPrint({
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 1)
NB_table=table("Prediction"= pred, "Actual" = df.test$klasifikasi)
conf.matNB <- confusionMatrix(pred, df.test$klasifikasi)
conf.matNB
})
output$scatterplot <- renderPlot(
{
produk_dataset<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = FALSE)
review <-as.character(produk_dataset$text)
s<-get_nrc_sentiment(review)
review_combine<-cbind(produk_dataset$text,s)
par(mar=rep(3,4))
barplot(colSums(s),col= rainbow(10),ylab='count',main='Analisis sentimen GWK')
},
height=400)
output$Wordcloud <- wordcloud2Output({
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:50,]
df.test<-data.frame[51:100,]
dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
#dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
})
}
shinyApp(ui = ui, server = server)
library(syuzhet) #untuk membaca fungsi get_nrc
dataLabel<- read.csv("labeling.csv")
ui <- fluidPage(
titlePanel("Analisis sentimen GWK"),
mainPanel(
tabsetPanel(type = "tabs",
#NB
tabPanel("Term Document Matrix and Statistic", verbatimTextOutput("result")),
#scatterplot
tabPanel("Analisis Emosi", plotOutput("scatterplot")),
# Plot
tabPanel("Data", DT::dataTableOutput('tbl1')),
# Output Data Dalam Tabel
tabPanel("Wordcloud", wordcloud2Output("Wordcloud"))
)
)
)
# SERVER
server <- function(input, output) {
# Output Data
output$tbl1 = DT::renderDataTable({
DT::datatable(dataLabel, options = list(lengthChange = FALSE))
})
output$result <-renderPrint({
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 1)
NB_table=table("Prediction"= pred, "Actual" = df.test$klasifikasi)
conf.matNB <- confusionMatrix(pred, df.test$klasifikasi)
conf.matNB
})
output$scatterplot <- renderPlot(
{
produk_dataset<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = FALSE)
review <-as.character(produk_dataset$text)
s<-get_nrc_sentiment(review)
review_combine<-cbind(produk_dataset$text,s)
par(mar=rep(3,4))
barplot(colSums(s),col= rainbow(10),ylab='count',main='Analisis sentimen GWK')
},
height=400)
output$Wordcloud <- wordcloud2Output({
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:50,]
df.test<-data.frame[51:100,]
dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
#dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
})
}
shinyApp(ui = ui, server = server)
library(syuzhet) #untuk membaca fungsi get_nrc
dataLabel<- read.csv("labeling.csv")
ui <- fluidPage(
titlePanel("Analisis sentimen GWK"),
mainPanel(
tabsetPanel(type = "tabs",
#NB
tabPanel("Term Document Matrix and Statistic", verbatimTextOutput("result")),
#scatterplot
tabPanel("Analisis Emosi", plotOutput("scatterplot")),
# Plot
tabPanel("Data", DT::dataTableOutput('tbl1')),
# Output Data Dalam Tabel
tabPanel("Wordcloud", wordcloud2Output("Wordcloud"))
)
)
)
# SERVER
server <- function(input, output) {
# Output Data
output$tbl1 = DT::renderDataTable({
DT::datatable(dataLabel, options = list(lengthChange = FALSE))
})
output$result <-renderPrint({
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 1)
NB_table=table("Prediction"= pred, "Actual" = df.test$klasifikasi)
conf.matNB <- confusionMatrix(pred, df.test$klasifikasi)
conf.matNB
})
output$scatterplot <- renderPlot(
{
produk_dataset<-read.csv("Review_GWK_Clean.csv",stringsAsFactors = FALSE)
review <-as.character(produk_dataset$text)
s<-get_nrc_sentiment(review)
review_combine<-cbind(produk_dataset$text,s)
par(mar=rep(3,4))
barplot(colSums(s),col= rainbow(10),ylab='count',main='Analisis sentimen GWK')
},
height=400)
output$Wordcloud <- wordcloud2Output({
=======
}, height=400)
output$Wordcloud <- renderPlot({
>>>>>>> a9a116762fe2276d1bf12bf46bae84217cdba960
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
inspect(dtm[1:10,1:20])
df.train<-data.frame[1:50,]
df.test<-data.frame[51:100,]
dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
#dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
convert_count <- function(x){
y<-ifelse(x>0,1,0)
y<-factor(y,levels=c(0,1),labels=c("no","yes"))
y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
})
}
shinyApp(ui = ui, server = server)
